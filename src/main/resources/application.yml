logging:
  level:
    root: INFO
    ch.arcticsoft.spring: DEBUG
    ch.arcticsoft.spring.web.ChatController: TRACE

    # Web / reactive server
    org.springframework.web: INFO
    org.springframework.web.reactive: INFO
    org.springframework.web.reactive.function.client.ExchangeFunctions: TRACE
    reactor.core.publisher: INFO
    reactor.netty.http.server: INFO
    reactor.netty.http.client: INFO

    # Spring AI (helps see prompts, tool calls depending on modules)
    org.springframework.ai: INFO
    org.springframework.ai.chat: TRACE
    org.springframework.ai.chat.client: DEBUG
    org.springframework.ai.tool: TRACE
    org.springframework.ai.chat.metadata.ChatResponseMetadata: INFO
    org.springaicommunity.tool.searcher: DEBUG
    org.springaicommunity.tool.searcher.LuceneToolSearcher: TRACE

    # Keep these quieter (they can be spammy)
    org.springframework.boot.autoconfigure: INFO
    org.springframework.context.annotation: INFO
     
    
server:
  reactive:
    session:
      timeout: 30m

reactor:
  netty:
    http:
      server:
        accessLogEnabled: true

spring:
  profiles:
    active: 
  ai:
   # mistralai:
   #   api-key: ${MISTRAL_API_KEY}
   #   chat:
   #     options:
   #       model: mistral-large-latest
   #       temerature: 0.2
   #       max-tokens: 1024
   # openai:
   #   enabled: false  
   #   api-key: ${OPENAI_API_KEY}
   #   chat:
   #     options:
   #       model: gpt-4o-mini        
    ollama:
      base-url: http://localhost:11434
      embedding:
        model: bge-m3
      api-key: ollama
      chat:
        options:
          model: hf.co/bartowski/swiss-ai_Apertus-8B-Instruct-2509-GGUF:Q4_K_M
          num-predict: 126
    vectorstore:
      qdrant:
        host: localhost
        port: 6334
        collection-name: springchat_tools_bg3_m3
        use-tls: false
        initialize-schema: true